{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c44d58",
   "metadata": {},
   "source": [
    "# Section-IV- Self Case Study-1_Pump it up-Data Mining the Water Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d51f3c0",
   "metadata": {},
   "source": [
    "## 6. Final model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4bfb8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from category_encoders import TargetEncoder, LeaveOneOutEncoder, WOEEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from prettytable import PrettyTable\n",
    "import category_encoders as ce\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "442a703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train_labels = pd.read_csv(\"train_lables.csv\")\n",
    "df = df_train.merge(df_train_labels, how='left', on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "49986e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing1(df):\n",
    "    df['funder'].fillna(value='Undefined',inplace=True) \n",
    "    df['funder'].replace(to_replace = '0', value ='Undefined' , inplace=True) #replacing '0' & missing values with 'Undefined'\n",
    "    top_30_funders = ['Government Of Tanzania','Undefined','Danida','Hesawa','Rwssp','World Bank','Kkkt','World Vision',\n",
    "                      'Unicef','Tasaf','District Council','Dhv','Private Individual','Dwsp','Norad','Germany Republi',\n",
    "                      'Tcrs','Ministry Of Water','Water','Dwe','Netherlands','Hifab','Adb','Lga','Amref','Fini Water',\n",
    "                      'Oxfam','Wateraid','Rc Church','Isf']\n",
    "    df.loc[~df[\"funder\"].isin(top_30_funders), \"funder\"] = \"other\"\n",
    "    \n",
    "    df['installer'].fillna(value='Undefined',inplace=True) \n",
    "    df['installer'].replace(to_replace = '0', value ='Undefined' , inplace=True) #replacing '0' category with 'Undefined'\n",
    "\n",
    "\n",
    "    df['installer'].replace(to_replace = (\"Gove\",\"Gover\",\"GOVERM\", \"GOVERN\", \"GOVERNME\", \"Governmen\",\"Government\",\n",
    "                                          \"GOVER\"), value =\"Government\", inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"RW\",\"RWE\",\"RWE /Community\",\"RWE Community\",\"RWE/ Community\",\"RWE/Community\",\n",
    "                                          \"RWE/DWE\",\"RWE/TCRS\",\"RWEDWE\",\"RWET/WESA\"), value =\"RWE\", inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"Commu\", \"Communit\", \"Community\", \"COMMUNITY BANK\",\n",
    "                                          \"Comunity\"), value =\"Community\", inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"Danda\",\"DANIAD\",\"Danid\",\"DANIDA\",\"DANIDA CO\",\"DANIDS\",\"DANNIDA\",\n",
    "                                          \"DANID\"), value =\"DANIDA\", inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"Cebtral Government\",\"Cental Government\",\"Centr\",\"Centra Government\",\"Centra govt\",\n",
    "                                          \"Central government\",\"Central govt\",\"Cetral government /RC\",\"Tanzania Government\",\n",
    "                                          \"TANZANIAN GOVERNMENT\"), value =\"Central Government\", inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"COUN\",\"Counc\",\"Council\",\"Distri\",\"District  Council\",\n",
    "                                          \"District Community j\",\"District Counci\", \"District council\",\n",
    "                                          \"District Council\"), value =\"District Council\", inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"Hesawa\",\"HESAW\",\"Hesewa\",\"HESAWA\"),value ='HESAWA' , inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"World Division\",\"World Visiin\",\"World vision\",\"World Vission\",\n",
    "                                          \"World Vision\"),value ='World Vision' , inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"Distric Water Department\",\"District Water Department\",\n",
    "                                          \"District water depar\",\"District water department\",\n",
    "                                          \"Water Department\"),value ='District water department' , inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"FINN WATER\",\"FinW\",\"FinWate\",\"FinWater\",\"Fini water\",\n",
    "                                          \"Fini Water\" ),value ='Fini Water' , inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"RC\",\"RC .Church\",\"RC C\",\"RC Ch\",\"RC Churc\",\"RC Church\",\n",
    "                                          \"RC CHURCH BROTHER\",\"RC church/CEFA\",\"RC church/Central Gover\",\n",
    "                                          \"RCchurch/CEFA\",\"RC CHURCH\"),value =\"RC Church\" , inplace=True)\n",
    "    df['installer'].replace(to_replace = (\"Villa\",\"VILLAGER\",\"Villagerd\",\"Villagers\",\"Villages\",\"Villege Council\",\n",
    "                                          \"Villi\",\"villigers\"),value =\"Villagers\" , inplace=True)\n",
    "\n",
    "\n",
    "    top_30_installer = [\"DWE\",\"Undefined\",\"Government\",\"DANIDA\",\"Community\",\"HESAWA\",\"RWE\",\"District Council\",\n",
    "                        \"Central Government\",\"KKKT\",\"TCRS\",\"World Vision\",\"CES\",\"Fini Water\",\"RC Church\",\"LGA\",\n",
    "                        \"WEDECO\",\"TASAF\",\"AMREF\",\"TWESA\",\"WU\",\"Dmdd\",\"ACRA\",\"Villagers\",\"SEMA\",\"DW\",\"OXFAM\",\"Da\",\n",
    "                        \"Idara ya maji\",\"UNICEF\"]\n",
    "\n",
    "\n",
    "    df.loc[~df[\"installer\"].isin(top_30_installer), \"installer\"] = \"other\"\n",
    "    \n",
    "    df['longitude'].replace(to_replace = 0 , value =34.07742669202832 , inplace=True)\n",
    "    df['population'].replace(to_replace = 0, value = 281.087167 , inplace=True)\n",
    "    df['construction_year'].replace(to_replace = 0, value = 1996, inplace=True)\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded']) #converting dates to 'datetime' datatype \n",
    "    df['operational_year'] = df.date_recorded.dt.year - df.construction_year\n",
    "    df.operational_year.head(5)\n",
    "    df.loc[df['operational_year']<0, 'operational_year'] = 0\n",
    "    \n",
    "    df.drop(columns=[\"construction_year\", \"date_recorded\",\"extraction_type\", \"extraction_type_class\",'payment_type',\n",
    "                \"quality_group\", \"quantity_group\",\"source_type\", \"source_class\",\"waterpoint_type_group\",'permit',\n",
    "                \"scheme_management\", 'id', 'amount_tsh','ward','wpt_name', 'num_private','subvillage','region_code',\n",
    "                'public_meeting','recorded_by','management_group','scheme_name'], inplace=True)\n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "aaa04c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizing1(df):\n",
    "    df = preprocessing1(df)\n",
    "    numeric_target_values = {'functional':1, 'non functional':0, 'functional needs repair':2}\n",
    "    df['status_group'] = df['status_group'].replace(numeric_target_values)\n",
    "\n",
    "    #encoding target variables manualy \n",
    "\n",
    "    numerical_features = ['gps_height','longitude', 'latitude', 'district_code','population', 'operational_year']\n",
    "    categorical_features = ['funder','installer','basin', 'region', 'lga', 'extraction_type_group','management', \n",
    "                            'payment', 'water_quality', 'quantity', 'source','waterpoint_type']\n",
    "    \n",
    "    y=df['status_group']\n",
    "    X = df.drop(columns = ['status_group'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "    \n",
    "    scaler1 = RobustScaler()\n",
    "    encoder1 = ce.TargetEncoder()\n",
    "\n",
    "    scaler = scaler1.fit(X_train[numerical_features])\n",
    "    scaler_pkl = joblib.dump(scaler, 'scaler.pkl')\n",
    "    X_train[numerical_features] = scaler.transform(X_train[numerical_features])\n",
    "    X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "    encoder = encoder1.fit(X_train[categorical_features], y_train)\n",
    "    encoder_pkl = joblib.dump(encoder, 'encoder.pkl')\n",
    "    X_train[categorical_features] = encoder.transform(X_train[categorical_features])\n",
    "    X_test[categorical_features] = encoder.transform(X_test[categorical_features])\n",
    "\n",
    "    smote1 = SMOTE(sampling_strategy = 'auto', n_jobs = -1)\n",
    "    X_smote_train, y_smote_train = smote1.fit_resample(X_train, y_train)\n",
    "    y_smote_train = pd.Series(y_smote_train)\n",
    "\n",
    "    smote2 = SMOTE(sampling_strategy = 'auto', n_jobs = -1)\n",
    "    X_smote_test, y_smote_test = smote2.fit_resample(X_test, y_test)\n",
    "    y_smote_test = pd.Series(y_smote_test)\n",
    "    \n",
    "    return X_smote_train, y_smote_train, X_smote_test, y_smote_test,  scaler_pkl, encoder_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4608fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1(df):\n",
    "    X_smote_train, y_smote_train, X_smote_test, y_smote_test, scaler_pkl, encoder_pkl  = vectorizing1(df)\n",
    "    \n",
    "    from xgboost import XGBClassifier\n",
    "    clf_xgb =XGBClassifier()\n",
    "    clf_xgb.fit(X_smote_train, y_smote_train)\n",
    "    model = joblib.dump(clf_xgb, 'model.pkl')\n",
    "    # making predictions on test set\n",
    "    y_pred_train = clf_xgb.predict(X_smote_train)\n",
    "    y_pred_train_proba = clf_xgb.predict_proba(X_smote_train)\n",
    "    # making predictions on test set\n",
    "    y_pred_test = clf_xgb.predict(X_smote_test)\n",
    "    y_pred_test_proba = clf_xgb.predict_proba(X_smote_test)\n",
    "\n",
    "    Bal_Acc_train = balanced_accuracy_score(y_smote_train, y_pred_train)\n",
    "    Bal_Acc_test = balanced_accuracy_score(y_smote_test, y_pred_test)\n",
    "\n",
    "    F1_train = f1_score(y_smote_train, y_pred_train, average=\"weighted\")\n",
    "    F1_test = f1_score(y_smote_test, y_pred_test, average=\"weighted\")\n",
    "    \n",
    "    roc_auc_score_train = roc_auc_score(y_smote_train, y_pred_train_proba, multi_class='ovr')\n",
    "    roc_auc_score_test = roc_auc_score(y_smote_test, y_pred_test_proba, multi_class='ovr')\n",
    "        \n",
    "    return Bal_Acc_train, Bal_Acc_test, F1_train, F1_test, roc_auc_score_train, roc_auc_score_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ff80c0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.859932790487269,\n",
       " 0.8149121451022827,\n",
       " 0.8595785120225174,\n",
       " 0.8141919402424288,\n",
       " 0.965501298178791,\n",
       " 0.9401492345110912,\n",
       " ['model.pkl'])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05292f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
